#!/usr/bin/python
# Copyright 2014 The Chromium Authors. All rights reserved.
# Use of this source code is governed by a BSD-style license that can be
# found in the LICENSE file.

"""A small tool to process and analyze trace logs.

To use Chrome tracing logs effectively, please refer to docs/profiling.md"""

import argparse
import json
import re
import sys

_TRACE_EVENTS = 'traceEvents'
_EVENT_TYPE = 'ph'
_EVENT_NAME = 'name'
_EVENT_TIMESTAMP = 'ts'
_METADATA_TYPE = 'M'


class Traces:

  def __init__(self, jsonfile):
    self._events = json.load(jsonfile)[_TRACE_EVENTS]
    self._events.sort(Traces._timestamp_cmp)

  @staticmethod
  def _timestamp_cmp(x, y):
    tsx = x[_EVENT_TIMESTAMP] if x[_EVENT_TIMESTAMP] else 0
    tsy = y[_EVENT_TIMESTAMP] if y[_EVENT_TIMESTAMP] else 0
    return tsx - tsy

  def filter(self, matching_function):
    filtered_events = []
    for rawevent in self._events:
      if _EVENT_TYPE in rawevent and rawevent[_EVENT_TYPE] == _METADATA_TYPE:
        # Metadata events are always added.
        filtered_events.append(rawevent)
      elif matching_function(rawevent):
        filtered_events.append(rawevent)
    self._events = filtered_events

  def normalize_time(self):
    first_timestamp = None
    for rawevent in self._events:
      if first_timestamp is None:
        if _EVENT_TIMESTAMP in rawevent and rawevent[_EVENT_TIMESTAMP] > 0:
          first_timestamp = rawevent[_EVENT_TIMESTAMP]
      if first_timestamp is not None and _EVENT_TIMESTAMP in rawevent:
        rawevent[_EVENT_TIMESTAMP] -= first_timestamp

  def dump(self, outputfile):
    json.dump({_TRACE_EVENTS: self._events}, outputfile)


def _parse_comma_separated_list(value):
  return value.split(',')


def _parse():
  parser = argparse.ArgumentParser()

  subparsers = parser.add_subparsers(title='commands')

  parser_filter = subparsers.add_parser('filter', help='Filter only events '
                                        'matching a certain name')
  parser_filter.add_argument('filename', type=str, help='trace.json file '
                             'generated by Chrome')
  parser_filter.add_argument('--names', type=_parse_comma_separated_list,
                             default=[], help='Comma-separated list of '
                             'allowed event names')
  parser_filter.add_argument('--output', type=str, required=True,
                             help='Write the filtered results to this file')
  parser_filter.add_argument('--regex', action='store_true',
                             help='Treat names as regular expressions')
  parser_filter.set_defaults(command='filter')

  parser_filter = subparsers.add_parser('normalize-time', help='Normalize '
                                        'timestamps so they start at the '
                                        'beginning of the trace')
  parser_filter.add_argument('filename', type=str, help='trace.json file '
                             'generated by Chrome')
  parser_filter.add_argument('--output', type=str, required=True,
                             help='Write the filtered results to this file')
  parser_filter.set_defaults(command='normalize-time')

  return parser.parse_args()


def main():
  OPTIONS = _parse()
  with open(OPTIONS.filename, 'r') as jsonfile:
    traces = Traces(jsonfile)

  if OPTIONS.command == 'filter':
    if OPTIONS.regex:
      names = [re.compile(r) for r in OPTIONS.names]

      def _match(s):
        return _EVENT_NAME in s and any(e.match(s[_EVENT_NAME]) for e in names)

      traces.filter(_match)
    else:
      def _match(s):
        return _EVENT_NAME in s and s[_EVENT_NAME] in OPTIONS.names
      traces.filter(_match)
  elif OPTIONS.command == 'normalize-time':
    traces.normalize_time()

  with open(OPTIONS.output, 'w') as outputfile:
    traces.dump(outputfile)


if __name__ == '__main__':
  sys.exit(main())
